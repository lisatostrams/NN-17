{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this assignment you will gain more insight into Hopfield networks and Boltzmann machines. Always show how you arrived at your answer. Hand in your assignment by adding the solutions to this notebook file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Exercise 1 (2 points)</H3>\n",
    "\n",
    "Consider a Hopfield network consisting of two variables $x_1$ and $x_2$ with thresholds $\\theta_1 = 0.5$ and $\\theta_2 = 0.5$ and a weight $w_{ij} = -1$. This network implements a so-called flip-flop. What is the energy function of this network, what are the possible energy levels, and what are the stable states?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Solutions Exercise 1</H3>\n",
    "\n",
    "Energy function:\n",
    "\n",
    "$E(x) = -\\frac{1}{2}(-x_1 x_2 -x_2 x_1) - (0.5x_1 + 0.5x_2) = x_1x_2-0.5x_1 - 0.5x_2$ \n",
    "\n",
    "Possible energy levels: see .png\n",
    "![possible E](table.png)\n",
    "\n",
    "Stable states:\n",
    "\n",
    "When $x_1$ and $x_2$ have state values that are not equal, the update rule does not change the energy level.\n",
    "When $x_1 = 1$ and $x_2 = 0$, $E(x) = -0.5$ and updating $x_1$ gives $a_1 = -1*0 +0.5 = 0.5$ and $f(a_1) = 1$. Then updating $x_2$ gives $a_2 = -1*1 +0.5 = -0.5$ and $f(a_2) = 0$. The energy level then is $-0.5$. The other way around, when $x_1 = 0$ and $x_2 = 1$, $E(x) = -0.5$ and updating $x_1$ gives $a_1 = -1*1 +0.5 = -0.5$ and $f(a_1) = 0$. Then updating $x_2$ gives $a_2 = -1*0 +0.5 = 0.5$ and $f(a_2) = 1$. The energy level then is $-0.5$ again. So this is where the values converge to. \n",
    "\n",
    "When $x_1$ and $x_2$ have state values that are equal, the energy level also converges to $E(x)= -0.5$. For $x_1,x_2 = 1$, after both states update $x_1 = f(a_1) = f(-1*1+0.5) = f(-0.5) = 0$ and $x_2 = f(a_2) = f(-1*0 +0.5) = f(0.5) = 1$ and as seen above, those states converge. For $x_1,x_2 = 0$, after both states update $x_1 = f(a_1) = f(-1*0+0.5) = f(0.5) = 1$ and $x_2 = f(a_2) = f(-1*1 +0.5) = f(-0.5) = 0$ and those states converge as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Exercise 2 (2 points)</H3>\n",
    "\n",
    "Consider a Hopfield network with\n",
    "\\begin{equation}\n",
    "\\mathbf{W} =\n",
    "\\left[\n",
    "\\begin{array}{llll}\n",
    "0 & -0.2 & -0.4 & 0\\\\\n",
    "-0.2 & 0 & 0.5 & 0.3\\\\\n",
    "-0.4 & 0.5 & 0 & 0.8\\\\\n",
    "0 & 0.3 & 0.8 & 0\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\end{equation}\n",
    "and \n",
    "$\\boldsymbol{\\theta} = (-0.5,-0.3,-0.8,0.2)$.\n",
    "What is the state of the Hopfield network after one sequential update of the first, second, third and fourth node when we start at the initial state $\\mathbf{x} = (0,1,1,1)$? What do you conclude?\n",
    "\n",
    "<H3>Solutions Exercise 2</H3>\n",
    "\n",
    "Update  first:\n",
    "$a_1 = -0.2*1 -0.4*1 + 0*1 - 0.5 = -1.1$ and $f(a_1) = 0$\n",
    "\n",
    "\n",
    "Upate second:\n",
    "$a_2 = -0.2*0 + 0.5*1 + 0.3*1 -0.3 = 0.5$ and $f(a_2) = 1$\n",
    "\n",
    "Update third:\n",
    "$a_3 = -0.4*0 + 0.5*1 + 0.3*1 -0.3 = 0.5$ and $f(a_3) = 1$\n",
    "\n",
    "Update fourth:\n",
    "$a_4 = 0*0 + 0.3*1 + 0.8*1 + 0.2 = 1.2$ and $f(a_4) = 1$\n",
    "\n",
    "You can conclude that when the initial state is $\\mathbf{x} = (0,1,1,1)$, the network converges to that state as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Exercise 4 (3 points)</H3>\n",
    "\n",
    "In this exercise you will test the Hopfield model as a constraint satisfaction system. Implement a function *optimize* which takes an argument $n$ and returns a length $n$ vector with all zeros except for a single one. This vector should be produced by running a Hopfield net with specific weights and thresholds (as dictated by this constraint satisfaction problem) until convergence. Show that your function works for different values of $n$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.]), -1.0)\n",
      "(array([ 0.,  0.,  1.,  0.]), -1.0)\n",
      "(array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.]), -1.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random as rand\n",
    "\n",
    "def activation(x_i, x,w_i,theta_i,N):\n",
    "    for j in range(N):\n",
    "        a = w_i[j] * x[j] + theta_i\n",
    "    return a\n",
    "\n",
    "def E(x,W,theta):\n",
    "    return -0.5*np.dot(np.dot(x.T,W),x)-np.dot(x.T,theta)\n",
    "    \n",
    "\n",
    "def optimize(n):\n",
    "    W = np.ones([n,n])*-2 - np.identity(n)*-2\n",
    "    theta = np.ones(n)\n",
    "    x = np.zeros(n)\n",
    "    \n",
    "    while(E(x,W,theta) >= 0):\n",
    "        i=rand.randint(0,n-1)\n",
    "        x[i] = activation(x[i],x, W[i,:], theta[i], n)\n",
    "        \n",
    "    \n",
    "    return x, E(x,W,theta)\n",
    "\n",
    "\n",
    "print optimize(10)\n",
    "print optimize(4)\n",
    "print optimize(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Exercise 5 (3 points)</H3>\n",
    "\n",
    "You will now implement your own Hopfield network and test its associative memory properties. In this exercise you can ignore the bias term and use the bipolar representation.\n",
    "* Below we provide the code to preprocess two images; call them $\\mathbf{x}_1$ and $\\mathbf{x}_2$. We also provide the code to evaluate Hopfield net training and testing\n",
    "* Write a function *w = hoptrain(x)* which takes a list of input patterns as argument and returns weights $\\mathbf{w}$ for a trained Hopfield network.\n",
    "* Write a function *y = hoptest(w,x,n)* which takes learned weights $\\mathbf{w}$ and an input pattern $\\mathbf{x}$ and updates all units in random order for $n$ times. The return value should be the updated states of the Hopfield network.\n",
    "* Test your Hopfield net by using $\\mathbf{x}_1$ and $\\mathbf{x}_2$ as an input pattern under different amounts of corruption (randomly changing pixel values). Visualise the corrupted images and the reconstructions. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x852ff98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#matplotlib inline\n",
    "\n",
    "import urllib2\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc as sp\n",
    "\n",
    "f=urllib2.urlopen(\"https://upload.wikimedia.org/wikipedia/en/2/24/Lenna.png\")\n",
    "\n",
    "x1 = mpimg.imread(f)\n",
    "x1 = np.mean(sp.imresize(x1,10),2)\n",
    "x1[x1 < np.mean(x1.flatten())] = -1    # Black\n",
    "x1[x1 >= np.mean(x1.flatten())] = 1 # White\n",
    "x1.astype('int32')\n",
    "\n",
    "x2 = np.fliplr(x1)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "imgplot = plt.imshow(x1, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "imgplot = plt.imshow(x2, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hoptrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2d5c38e75a39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# train Hopfield net\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhoptrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;31m# corrupt images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hoptrain' is not defined"
     ]
    }
   ],
   "source": [
    "# train Hopfield net\n",
    "\n",
    "w = hoptrain([x1,x2])\n",
    "\n",
    "# corrupt images\n",
    "\n",
    "n = np.floor(x1.size/2)\n",
    "\n",
    "cx1 = x1.copy()\n",
    "p = np.random.permutation(x1.size)\n",
    "cx1[np.unravel_index(p[:n],x1.shape)] = np.random.randint(0,1,n)\n",
    "\n",
    "cx2 = x2.copy()\n",
    "p = np.random.permutation(x2.size)\n",
    "cx2[np.unravel_index(p[:n],x2.shape)] = np.random.randint(0,1,n)\n",
    "\n",
    "# test associative memory properties\n",
    "\n",
    "p1 = hoptest(cx1,w,1)\n",
    "p2 = hoptest(cx2,w,2)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(221)\n",
    "imgplot = plt.imshow(cx1, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.subplot(222)\n",
    "imgplot = plt.imshow(cx2, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.subplot(221)\n",
    "imgplot = plt.imshow(p1, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.subplot(222)\n",
    "imgplot = plt.imshow(p2, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
