{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will work on multilayer neural networks. Always show how you arrived at your answer. Hand in your assignment by adding the solutions to this notebook file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Exercise 1 (3 points)</H3>\n",
    "\n",
    "1. Derive $\\frac{d f}{d a}$ for the sigmoid activation function:\n",
    "$\n",
    "f(a) = \\frac{1}{1 + \\exp(-a)}\n",
    "$\n",
    "and show that your derivation is equal to $f(a)(1-f(a))$.\n",
    "2. Show that the error $\\delta_j$  for an output unit of a multilayer network in case of the squared loss $E^n(\\mathbf{w}) = \\frac{1}{2} \\sum_k (y^n_k - t^n_k)^2$  and a sigmoid activation function is equal to:\n",
    "\\begin{equation}\n",
    "\\delta_j = (y^n_j - t^n_j) y^n_j (1 - y^n_j).\n",
    "\\end{equation}\n",
    "3. Multilayer neural networks assume that the activation function is both differentiable and non-linear. Explain why it must be differentiable and show mathematically that linear activation functions ($f(a) = a$) reduce multilayer neural networks to single layer neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Solution 1</H3>\n",
    "\n",
    "1. $\\frac{d f}{d a} = \\frac{d \\frac{1}{1+\\exp(-a)}}{d a} = \\frac{d \\frac{1}{h}}{d h} \\frac{d (1+\\exp(-a))}{d a} = -\\frac{1}{h^2} \\exp(-a) = -\\frac{1}{(1+\\exp(-a))^2} \\exp(-a) = -\\frac{\\exp(-a)}{(1+exp(-a))^2} $\n",
    "\n",
    "The given function  $f(a)(1-f(a))$ can be rewritten as $\\frac{1}{1+\\exp(-a)} \\left ( \\frac{1+\\exp(-a)}{1+\\exp(-a)} - \\frac{1}{1+\\exp(-a)} \\right ) =  \\frac{1+\\exp(-a)}{(1+\\exp(-a))^2} - \\frac{1}{(1+\\exp(-a))^2} = \\frac{1}{1+\\exp(-a)} - \\frac{1}{(1+\\exp(-a))^2} = -\\frac{1- (1+\\exp(-a))}{(1+\\exp(-a))^2} = -\\frac{\\exp(-a)}{(1+\\exp(-a))^2} $ which is the same function as derived before. \n",
    " \n",
    "2. $\\delta_j =  \\frac{\\partial E^n }{\\partial a_j } = \\frac{\\partial E^n }{\\partial y^n_j } \\frac{\\partial y^n_j }{\\partial a_j } = \\frac{\\partial E^n }{\\partial y^n_j } \\frac{\\partial f(a_j) }{\\partial a_j } = \\frac{\\partial \\frac{1}{2} (y^n_j - t^n_j) }{\\partial y^n_j } \\frac{\\partial f(a_j) }{\\partial a_j } = (y^n_j - t^n_j) \\frac{\\partial f(a_j) }{\\partial a_j }  = (y^n_j - t^n_j) f(a)(1-f(a)) = (y^n_j - t^n_j)y^n_j(1-y^n_j)  $\n",
    "\n",
    "3. \n",
    "\n",
    "y = w3w2w1x = ux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Exercise 2 (7 points)</H3>\n",
    "\n",
    "In the following exercise you will learn to implement the backpropagation algorithm. We provide most of the code. It is your job to implement the essential missing steps. We consider a problem where you need to classify which digit (0,1,...,9) each 20x20 pixel image, representing a handwritten digit, belongs to. We first read in the required training and test data from a matlab file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "\n",
    "# read data from mat file\n",
    "import scipy.io\n",
    "mat = scipy.io.loadmat('MLP_data.mat')\n",
    "    \n",
    "X_train = mat['X_training']\n",
    "X_test = mat['X_test']\n",
    "T_train = mat['T_training']\n",
    "T_test = mat['T_test']\n",
    "\n",
    "# take out all constant pixels since they are noninformative anyway\n",
    "idx = (np.std(X_train,1) != 0) & (np.std(X_test,1) != 0)\n",
    "X_train = X_train[idx,:]\n",
    "X_test = X_test[idx,:]\n",
    "\n",
    "# zscore data\n",
    "X_train = np.array(ss.zscore(X_train,1))\n",
    "X_test = np.array(ss.zscore(X_test,1))\n",
    "\n",
    "# add bias terms\n",
    "X_train = np.vstack([np.ones([1,X_train.shape[1]]),X_train])\n",
    "X_test = np.vstack([np.ones([1,X_test.shape[1]]),X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now provide an implementation of the sigmoid function and its derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Sigmoid function; returns function value and gradient\n",
    "    \"\"\"\n",
    "\n",
    "    fx = 1.0 / (1 + np.exp(-x))\n",
    "    gradx = fx * (1 - fx)\n",
    "\n",
    "    return fx, gradx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the loss function. For simplicity we use the squared error loss. Ideally however we would want to use the cross-entropy as a loss function but we ignore this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error(f_a_3,T):\n",
    "    \"\"\"\n",
    "    Computes squared error divided by number of trials\n",
    "    \n",
    "    Input:\n",
    "    f_a_3 : MLP output states\n",
    "    T   : noutput x ntrials targets\n",
    "\n",
    "    Output:\n",
    "    E_w        : squared error\n",
    "    \n",
    "    \"\"\"\n",
    "   \n",
    "    ntrials = T.shape[1]\n",
    "\n",
    "    E_w = 1.0 / (2 * ntrials) * np.sum(np.sum((f_a_3 - T) ** 2))\n",
    "   \n",
    "    return E_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define the forward pass for our MLP. Please fill in the missing details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forwardprop(W_1, W_2, X):\n",
    "    \"\"\"\n",
    "    Performs forward propagation\n",
    "    \n",
    "    Input:\n",
    "    W_1 : nhidden x ninput input-to-hidden weight matrix\n",
    "    W_2 : noutput x nhidden hidden-to-output weight matrix\n",
    "    X   : ninput x ntrials input data\n",
    "    \n",
    "    Output:\n",
    "    f_a_2 : MLP hidden unit states\n",
    "    f_a_3 : MLP output states\n",
    "    grad_f_a_2 : gradient of the hidden unit activation function\n",
    "    grad_f_a_3 : gradient of the output unit activation function\n",
    "    \"\"\"\n",
    "    \n",
    "    # You should now implement the forward propagation function. Your\n",
    "    # implementation should compute and return the outputs of the second and\n",
    "    # third layer units as well as their gradients.\n",
    "\n",
    "    # First, compute the inputs of the second layer units (i.e. a_2). Write\n",
    "    # your code below:\n",
    "    # -------------------------------------------------------------------------\n",
    "    a_2 = np.dot(W_1, X)\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # Once you have computed a_2, use it with the sigmoid function that you\n",
    "    # have implemented (i.e. sigmoid) to compute the outputs of the second\n",
    "    # layer units (i.e. f_a_2) and their gradients (i.e. grad_f_a_2). Write\n",
    "    # your code below:\n",
    "    # -------------------------------------------------------------------------\n",
    "    f_a_2, grad_f_a_2 = sigmoid(a_2) \n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # Then, compute the inputs of the third layer units (i.e. a_3). Write your\n",
    "    # code below:\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    a_3 = np.dot(W_2, f_a_2)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # Once you have computed a_3, use it with the sigmoid function that you\n",
    "    # have implemented (i.e. sigmoid) to compute the outputs of the third layer\n",
    "    # units (i.e. f_a_3) and their gradients (i.e. grad_f_a_3). Write your code\n",
    "    # below:\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    f_a_3, grad_f_a_3 = sigmoid(a_3)\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    return f_a_2, f_a_3, grad_f_a_2, grad_f_a_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the backward pass for our MLP. Please fill in the missing details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backprop(f_a_2, f_a_3, grad_f_a_2, grad_f_a_3, T, W_2, X):\n",
    "    \"\"\"\n",
    "    Performs backpropagation step\n",
    "    \n",
    "    Input:\n",
    "    f_a_2 : MLP hidden unit states\n",
    "    f_a_3 : MLP output states\n",
    "    grad_f_a_2 : gradient of the hidden unit activation function\n",
    "    grad_f_a_3 : gradient of the output unit activation function\n",
    "    T   : noutput x ntrials targets\n",
    "    W_2 : noutput x nhidden hidden-to-output weight matrix\n",
    "    X   : ninput x ntrials input data\n",
    "    \n",
    "    Output:\n",
    "    grad_E_w_1 : ntrials x 1 gradient of the error w.r.t W_1\n",
    "    grad_E_w_2 : ntrials x 1 gradient of the error w.r.t W_2\n",
    "    \"\"\"\n",
    "        \n",
    "    # You should now implement the back propagation function. Your\n",
    "    # implementation should compute and return the gradients of the error\n",
    "    # function.\n",
    "\n",
    "    # First, compute the errors of the second and third layer units (i.e.\n",
    "    # delta_2 and delta_3). Write you code below:\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "\n",
    "    delta_3 = (f_a_3 - T) * grad_f_a_3\n",
    "                   \n",
    "    delta_2 = grad_f_a_2 *(np.dot(W_2.T, delta_3))\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # Once you have computed delta_2 and delta_3, use them to compute the\n",
    "    # gradients of the error function (i.e. grad_E_w_1 and grad_E_w_2). Write\n",
    "    # your code below:\n",
    "    # -------------------------------------------------------------------------\n",
    " \n",
    "    # Add your solution here.\n",
    "    grad_E_w_2 = np.dot(delta_3, f_a_2.T)\n",
    "    \n",
    "    grad_E_w_1 = np.dot(delta_2, X.T)\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    return grad_E_w_1, grad_E_w_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we provide the script with which you can test your MLP implementation. You should see that the error decreases for both the training and the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100 / 2000; Train error: [ 0.14037091]; Test error: [ 0.1575606]\n",
      "Iteration: 200 / 2000; Train error: [ 0.07859062]; Test error: [ 0.10517099]\n",
      "Iteration: 300 / 2000; Train error: [ 0.06004385]; Test error: [ 0.09220482]\n",
      "Iteration: 400 / 2000; Train error: [ 0.0501969]; Test error: [ 0.08735554]\n",
      "Iteration: 500 / 2000; Train error: [ 0.04364136]; Test error: [ 0.08561769]\n",
      "Iteration: 600 / 2000; Train error: [ 0.03890172]; Test error: [ 0.08511539]\n",
      "Iteration: 700 / 2000; Train error: [ 0.03518677]; Test error: [ 0.08498987]\n",
      "Iteration: 800 / 2000; Train error: [ 0.03218403]; Test error: [ 0.08499936]\n",
      "Iteration: 900 / 2000; Train error: [ 0.02969919]; Test error: [ 0.08514915]\n",
      "Iteration: 1000 / 2000; Train error: [ 0.02766153]; Test error: [ 0.08536537]\n",
      "Iteration: 1100 / 2000; Train error: [ 0.02593859]; Test error: [ 0.08559919]\n",
      "Iteration: 1200 / 2000; Train error: [ 0.02439936]; Test error: [ 0.08583459]\n",
      "Iteration: 1300 / 2000; Train error: [ 0.02307425]; Test error: [ 0.08593792]\n",
      "Iteration: 1400 / 2000; Train error: [ 0.02195449]; Test error: [ 0.08607612]\n",
      "Iteration: 1500 / 2000; Train error: [ 0.0209774]; Test error: [ 0.08624926]\n",
      "Iteration: 1600 / 2000; Train error: [ 0.02011438]; Test error: [ 0.08643409]\n",
      "Iteration: 1700 / 2000; Train error: [ 0.01934573]; Test error: [ 0.08661946]\n",
      "Iteration: 1800 / 2000; Train error: [ 0.01865782]; Test error: [ 0.08679847]\n",
      "Iteration: 1900 / 2000; Train error: [ 0.01803177]; Test error: [ 0.08696729]\n",
      "Iteration: 2000 / 2000; Train error: [ 0.01743907]; Test error: [ 0.08711169]\n"
     ]
    }
   ],
   "source": [
    "nepochs = 2000\n",
    "learning_rate = 0.001\n",
    "\n",
    "ninput = X_train.shape[0]\n",
    "noutput = T_train.shape[0]\n",
    "nhidden = 15\n",
    "\n",
    "# initialize weights\n",
    "r = np.sqrt(6)/np.sqrt(nhidden+ninput)\n",
    "W_1 = np.random.uniform(-r, r, [nhidden,ninput])\n",
    "\n",
    "r = np.sqrt(6)/np.sqrt(nhidden+ninput)\n",
    "W_2 = np.random.uniform(-r, r, [noutput,nhidden])\n",
    "\n",
    "# keep track of errors\n",
    "train_error = np.zeros([nepochs+1,1])\n",
    "test_error = np.zeros([nepochs+1,1])\n",
    "\n",
    "# training\n",
    "for epoch in xrange(0,nepochs):\n",
    "\n",
    "    # First, use the forward propagation function that you have implemented\n",
    "    # (i.e. forwardprop) to compute the outputs of the second and third layer\n",
    "    # units (i.e. f_a_2 and f_a_3) as well as their gradients (i.e. grad_f_a_2\n",
    "    # and grad_f_a_3). Write your code below:\n",
    "    # -------------------------------------------------------------------------\n",
    "    [f_a_2, f_a_3, grad_f_a_2, grad_f_a_3] = forwardprop(W_1, W_2, X_train)\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # compute error\n",
    "    train_error[epoch] = error(f_a_3, T_train)\n",
    "    test_error[epoch] = error(forwardprop(W_1, W_2, X_test)[1], T_test)\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "         print('Iteration: ' + str(epoch+1) + ' / ' + str(nepochs) + '; Train error: ' \n",
    "               + str(train_error[epoch])) + '; Test error: ' + str(test_error[epoch])\n",
    " \n",
    "    # Once you have computed f_a_2, f_a_3, grad_f_a_2 and grad_f_a_3, use them\n",
    "    # with the back propagation function that you have implemented (i.e.\n",
    "    # backprop) to compute the gradients of the error function (i.e. grad_E_w_1\n",
    "    # and grad_E_w_2). Write your code below:\n",
    "    # -------------------------------------------------------------------------\n",
    "    [grad_E_w_1, grad_E_w_2] = backprop(f_a_2, f_a_3, grad_f_a_2, grad_f_a_3, T_train, W_2, X_train)\n",
    "    # -------------------------------------------------------------------------\n",
    "             \n",
    "    W_1 = W_1 - learning_rate * grad_E_w_1                                 \n",
    "    W_2 = W_2 - learning_rate * grad_E_w_2                                                                            \n",
    "    \n",
    "# get error after the last update\n",
    "train_error[-1] = error(forwardprop(W_1, W_2, X_train)[1], T_train)\n",
    "test_error[-1] = error(forwardprop(W_1, W_2, X_test)[1], T_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a plot of the decrease in training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n51AwM7N+/x/GbfukTv4upQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd156eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd156320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create plot here\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_error)\n",
    "plt.title('Error over epochs training set')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(test_error)\n",
    "plt.title('Error over epochs training set')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
